{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#reload source files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from generation.cbf import generate_pattern_data, generate_bell, generate_cylinder, generate_funnel\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 100\n",
    "test_size = 50\n",
    "length = 600\n",
    "\n",
    "feature_numbers = list(range(10, 160, 70))\n",
    "important_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_amplitude = 10\n",
    "avg_pattern_length = 20\n",
    "variance_pattern_length = 5 \n",
    "variance_amplitude = 2\n",
    "clean = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_clean = ['ft'+str(i) for i in range(important_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature_number in feature_numbers:\n",
    "    columns_noisy = ['ft'+str(i) for i in range(important_features, feature_number)]\n",
    "    columns = columns_clean + columns_noisy\n",
    "    \n",
    "    train = pd.DataFrame(columns=columns+['experiment', 'label'], data=0, index=np.arange(2*train_size*length))\n",
    "    train['experiment'] = np.reshape([[i]*length for i in range(train_size*2)], 2*train_size*length)\n",
    "    train['label'] = [0]*length*train_size + [1]*train_size*length\n",
    "    \n",
    "    for i in range(train_size):\n",
    "        for col in columns_clean:\n",
    "            train.loc[train['experiment']==i, col] = generate_pattern_data(length, avg_pattern_length, \n",
    "                                                                           avg_amplitude, clean, \n",
    "                                                                           variance_pattern_length,\n",
    "                                                                           variance_amplitude,\n",
    "                                                                           [generate_bell], False)\n",
    "        for col in columns_noisy:\n",
    "            train.loc[train['experiment']==i, col] = np.random.normal(5, 2.5, length)\n",
    "            \n",
    "    for i in range(train_size, 2*train_size):\n",
    "        for col in columns_clean:\n",
    "            train.loc[train['experiment']==i, col] = generate_pattern_data(length, avg_pattern_length, \n",
    "                                                                           avg_amplitude, clean, \n",
    "                                                                           variance_pattern_length,\n",
    "                                                                           variance_amplitude,\n",
    "                                                                           [generate_funnel], False)\n",
    "        for col in columns_noisy:\n",
    "            train.loc[train['experiment']==i, col] = np.random.normal(5, 2.5, length)\n",
    "            \n",
    "    train.to_csv('../data/scalability_robustness/synthetic_robustness'+str(feature_number)+'_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature_number in feature_numbers:\n",
    "    columns_noisy = ['ft'+str(i) for i in range(important_features, feature_number)]\n",
    "    columns = columns_clean + columns_noisy\n",
    "    test = pd.DataFrame(columns=columns+['experiment', 'label'], data=0, index=np.arange(2*test_size*length))\n",
    "    test['experiment'] = np.reshape([[i]*length for i in range(test_size*2)], 2*test_size*length)\n",
    "    test['label'] = [0]*test_size*length + [1]*test_size*length\n",
    "    \n",
    "    for i in range(test_size):\n",
    "        for col in columns_clean:\n",
    "            test.loc[test['experiment']==i, col] = generate_pattern_data(length, avg_pattern_length, \n",
    "                                                                           avg_amplitude, clean, \n",
    "                                                                           variance_pattern_length,\n",
    "                                                                           variance_amplitude,\n",
    "                                                                           [generate_bell], False)\n",
    "        for col in columns_noisy:\n",
    "            test.loc[test['experiment']==i, col] = np.random.normal(5, 2.5, length)\n",
    "        \n",
    "    for i in range(test_size, 2*test_size):\n",
    "        for col in columns_clean:\n",
    "            test.loc[test['experiment']==i, col] = generate_pattern_data(length, avg_pattern_length, \n",
    "                                                                           avg_amplitude, clean, \n",
    "                                                                           variance_pattern_length, \n",
    "                                                                           variance_amplitude,\n",
    "                                                                           [generate_funnel], False)\n",
    "        for col in columns_noisy:\n",
    "            test.loc[test['experiment']==i, col] = np.random.normal(5, 2.5, length)\n",
    "           \n",
    "    test.to_csv('../data/scalability_robustness/synthetic_robustness'+str(feature_number)+'_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
